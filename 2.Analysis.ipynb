{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph_tool.all import *\n",
    "import pickle\n",
    "import matplotlib\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import collections\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adri's path\n",
    "os.chdir('/Users/adriana/Desktop/CEU/_COURSES/Dynamical/FinalProject/data')\n",
    "\n",
    "# Elsa's path\n",
    "#os.chdir('/home/utilisateur/Desktop/Courses/Dynamics_on_networks/project/version_2/FinalProject/data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIST OF FUNCTIONS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RECIPROCAL EVENTS\n",
    "#____________________\n",
    "\n",
    "\n",
    "# Function which take in input the graphs (g_D,g) and return (g_D) with properties of the nodes: \n",
    "    # - 1. number of reciprocal events: 'n_rec'\n",
    "    # - 2. probability of reciprocal events: 'proba_rec_event'\n",
    "    # - 3. probability of reciprocal links : 'proba_rec_link'\n",
    "\n",
    "def rec_nodes(g_D,g):\n",
    "    prop =[g_D.ep[p] for p in dict(g_D.edge_properties).keys()]\n",
    "    \n",
    "    \n",
    "    n_rec_event = g.new_vertex_property(\"double\")\n",
    "    g.vp.n_rec_event= n_rec_event\n",
    "    \n",
    "    n_rec_link = g.new_vertex_property(\"double\")\n",
    "    g.vp.n_rec_link= n_rec_link\n",
    "      \n",
    "    proba_rec_event = g.new_vertex_property(\"double\") \n",
    "    g.vp.proba_rec_event= proba_rec_event\n",
    "    \n",
    "    proba_rec_link = g.new_vertex_property(\"double\")     \n",
    "    g.vp.proba_rec_link= proba_rec_link\n",
    "    \n",
    "    \n",
    "    #---\n",
    "    n_tot_events = g.new_vertex_property(\"double\") \n",
    "    g.vp.n_tot_events= n_tot_events\n",
    "    \n",
    "    \n",
    "    for node in g_D.vertices():\n",
    "        counter_rec_event = 0\n",
    "        counter_rec_link = 0\n",
    "        \n",
    "        events = g_D.get_all_edges(node,eprops = prop)\n",
    "        neighbors = g.get_all_neighbors(node)\n",
    "        \n",
    "        \n",
    "        #---\n",
    "        g.vp.n_tot_events[node] = len(events)\n",
    "        \n",
    "        for neighbor in neighbors:\n",
    "            rows, cols = np.where(events[:,:2] == neighbor)\n",
    "            events_node_nei = sorted(events[rows], key = lambda x: x[5])\n",
    "            \n",
    "            binary_rec = [0 if events_node_nei[k][0]==events_node_nei[k+1][0] \n",
    "                          else 1 for k in range(len(events_node_nei)-1)].count(1)\n",
    "            \n",
    "            # counting n of rec events (on g_D)\n",
    "            counter_rec_event += binary_rec\n",
    "            \n",
    "            \n",
    "            # countinf n of rec links (on g)\n",
    "            if binary_rec !=0: \n",
    "                counter_rec_link +=1\n",
    "            \n",
    "        g.vp.n_rec_event[node] = counter_rec_event\n",
    "        g.vp.n_rec_link[node] = counter_rec_link\n",
    "        \n",
    "        \n",
    "        \n",
    "        if len(events)==0:\n",
    "            g.vp.proba_rec_event[node] = 0\n",
    "            g.vp.proba_rec_link[node] = 0\n",
    "        else:\n",
    "            #print('nn', len(neighbors))\n",
    "            #print('e', len(events)) \n",
    "            g.vp.proba_rec_event[node] = counter_rec_event / (len(events))\n",
    "            g.vp.proba_rec_link[node] = counter_rec_link / (len(neighbors))\n",
    "               \n",
    "    return(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BURSTINESS\n",
    "#____________\n",
    "\n",
    "def burstiness(distri_intertimes):\n",
    "    '''\n",
    "    range: from -1 (deterministic) to +1 (super bursty)\n",
    "    '''\n",
    "    \n",
    "    mean = np.mean(distri_intertimes)\n",
    "    std = np.std(distri_intertimes)\n",
    "    return((std-mean)/(std+mean))\n",
    "\n",
    "\n",
    "\n",
    "# Reciprocal events\n",
    "#--------------------\n",
    "\n",
    "# Function which takes as an input g_D and return it with the nodes property:\n",
    "    # - 1. burtiness of the reciprocal 'burst_rec'\n",
    "    # - 2. intertime dist of the reciprocal event 'intertime_rec'\n",
    "    \n",
    "def burst_rec_nodes(g_D,g):\n",
    "    \n",
    "    prop =[g_D.ep[p] for p in dict(g_D.edge_properties).keys()]\n",
    "    \n",
    "    burst_rec = g.new_vertex_property(\"double\") \n",
    "    intertime_rec = g.new_vertex_property(\"vector<double>\") \n",
    "    \n",
    "    g.vp.burst_rec= burst_rec\n",
    "    g.vp.intertime_rec= intertime_rec\n",
    "    \n",
    "    for node in g_D.vertices():\n",
    "        \n",
    "        list_burstiness_rec = []\n",
    "        node_intertimes_rec = []\n",
    "        \n",
    "        events = g_D.get_all_edges(node,eprops = prop)\n",
    "    \n",
    "        for neighbor in g.get_all_neighbors(node):\n",
    "            rows, cols = np.where(events[:,:2] == neighbor)\n",
    "            events_node_nei = sorted(events[rows], key = lambda x: x[5])\n",
    "            \n",
    "            intertime_rec = [events_node_nei[k+1][5]-events_node_nei[k][5]\n",
    "                             for k in range(len(events_node_nei)-1) if\n",
    "                             events_node_nei[k][0]!=events_node_nei[k+1][0]]\n",
    "            \n",
    "            node_intertimes_rec.extend(intertime_rec) \n",
    "            list_burstiness_rec += intertime_rec\n",
    "        \n",
    "        #print(node_intertimes_rec)\n",
    "        # Crating properties \n",
    "        g.vp.burst_rec[node] = burstiness(list_burstiness_rec)\n",
    "        g.vp.intertime_rec[node] = np.array(node_intertimes_rec)\n",
    "        \n",
    "        \n",
    "    return(g)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NON- Reciprocal events\n",
    "#-----------------------\n",
    "\n",
    "# Function which takes as an input g_D and return it with the nodes property: \n",
    "    # - 1. burstiness of the non-reciprocal event: 'burst_no_rec'\n",
    "    # - 2. intertime dist of the non-reciprocal event: 'intertime_no_rec'\n",
    "\n",
    "def burst_no_rec_nodes(g_D,g):\n",
    "    \n",
    "    prop =[g_D.ep[p] for p in dict(g_D.edge_properties).keys()]\n",
    "    \n",
    "    burst_no_rec = g.new_vertex_property(\"double\") \n",
    "    intertime_no_rec = g.new_vertex_property(\"vector<double>\") \n",
    "    \n",
    "    g.vp.burst_no_rec= burst_no_rec\n",
    "    g.vp.intertime_no_rec= intertime_no_rec\n",
    "    \n",
    "    for node in g_D.vertices():\n",
    "        \n",
    "        list_burstiness_no_rec = []\n",
    "        node_intertimes_no_rec = []\n",
    "        \n",
    "        events = g_D.get_all_edges(node,eprops = prop)\n",
    "        \n",
    "        for neighbor in g.get_all_neighbors(node):\n",
    "        \n",
    "            rows, cols = np.where(events[:,:2] == neighbor)\n",
    "            events_node_nei = sorted(events[rows], key = lambda x: x[5])\n",
    "            \n",
    "            intertime_no_rec = [events_node_nei[k+1][5]-events_node_nei[k][5] \n",
    "                               for k in range(len(events_node_nei)-1) \n",
    "                                 if events_node_nei[k][0]==events_node_nei[k+1][0]]\n",
    "            \n",
    "            list_burstiness_no_rec += intertime_no_rec\n",
    "            node_intertimes_no_rec.extend(intertime_no_rec)\n",
    "            \n",
    "            \n",
    "        g.vp.burst_no_rec[node] = burstiness(list_burstiness_no_rec)\n",
    "        g.vp.intertime_no_rec[node] = np.array(node_intertimes_no_rec)\n",
    "        \n",
    "    return(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALL events\n",
    "#-----------------------\n",
    "\n",
    "# Function which takes as an input g_D and return it with the nodes property: \n",
    "    # - 1. burstiness of the all event: 'burst'\n",
    "    # - 2. intertime dist of all event: 'intertime'\n",
    "\n",
    "def burst_nodes(g_D,g):\n",
    "    \n",
    "    prop =[g_D.ep[p] for p in dict(g_D.edge_properties).keys()]\n",
    "    \n",
    "    burst = g.new_vertex_property(\"double\") \n",
    "    intertime = g.new_vertex_property(\"vector<double>\") \n",
    "    \n",
    "    g.vp.burst= burst\n",
    "    g.vp.intertime= intertime\n",
    "    \n",
    "    for node in g_D.vertices():\n",
    "        list_burstiness= []\n",
    "        node_intertimes= []\n",
    "        \n",
    "        events = g_D.get_all_edges(node,eprops = prop)\n",
    "        \n",
    "        for neighbor in g.get_all_neighbors(node):\n",
    "        \n",
    "            rows, cols = np.where(events[:,:2] == neighbor)\n",
    "            events_node_nei = sorted(events[rows], key = lambda x: x[5])\n",
    "            \n",
    "            intertime = [events_node_nei[k+1][5]-events_node_nei[k][5] \n",
    "                         for k in range(len(events_node_nei)-1)]\n",
    "            \n",
    "            list_burstiness += intertime\n",
    "            node_intertimes.extend(intertime)            \n",
    "            \n",
    "        g.vp.burst[node] = burstiness(list_burstiness)\n",
    "        \n",
    "        g.vp.intertime[node] = np.array(node_intertimes)\n",
    "        \n",
    "    return(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edge properties\n",
    "______"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "# this a test graph to check the functions \n",
    "\n",
    "name = 'test'\n",
    "\n",
    "g_D = load_graph('./graphs_raw/'+name+\"_g_d.xml.gz\")\n",
    "g = load_graph('./graphs_raw/'+name+\"_g.xml.gz\")\n",
    "\n",
    "\n",
    "#g_D.remove_edge(g_D.edge(0,2) )\n",
    "#g_D.add_edge(2,0)\n",
    "#g_D.ep.ts_sec[(2,0)] = 2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "g = rec_nodes(g_D,g)\n",
    "g = burst_rec_nodes(g_D,g)\n",
    "g = burst_no_rec_nodes(g_D,g)\n",
    "g = burst_nodes(g_D,g)\n",
    "\n",
    "\n",
    "#graph_draw(g, vertex_text= g.vertex_index, edge_text= g.ep.p_Erec,output_size=(250, 250) )\n",
    "#graph_draw(g, vertex_text= g.vertex_index,edge_text= g_D.ep.ts_sec, output_size=(250, 250) )\n",
    "#graph_draw(g, vertex_text= g.vp.burst, output_size=(250, 250) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_link_prop(g,g_D):\n",
    "    \n",
    "    '''\n",
    "    Note the edge properties will be saved  on g!!! \n",
    "        ie. on the aggregate static network\n",
    "    \n",
    "    In this function we compute: \n",
    "    - Balance at edge level: Given e edge from i to j.\n",
    "        be = max(Ni, Nj)/(Ni+Nj)\n",
    "   \n",
    "    - P_Erec at edge level: Probability of having a reciprocal event for a given sequence of events be node ij\n",
    "        p_Erec = n_rec/(ni+nj-1)\n",
    "        \n",
    "    - Intertime\n",
    "    \n",
    "    - Burstiness at edge level\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # 1. Creating edge (link) property \n",
    "    balance = g.new_edge_property(\"double\") \n",
    "    g.ep.balance= balance\n",
    "    \n",
    "    p_Erec = g.new_edge_property(\"double\") # prop of reciprocity at link level \n",
    "    g.ep.p_Erec= p_Erec\n",
    "    \n",
    "    burts = g.new_edge_property(\"double\") \n",
    "    g.ep.burts= burts\n",
    "    \n",
    "    n_events= g.new_edge_property(\"double\") \n",
    "    g.ep.n_events= n_events\n",
    "    \n",
    "    intertime = g.new_edge_property(\"vector<double>\") \n",
    "    g.ep.intertime= intertime\n",
    "    \n",
    "    \n",
    "    ite= 1\n",
    "    N=str(g.num_edges())\n",
    "    \n",
    "    for e in g.edges(): # for every edges in the g graph\n",
    "        sys.stdout.write('\\r' +'  edges n: '+ str(ite)+'/'+N )\n",
    "\n",
    "        i = e.source() # node i\n",
    "        j = e.target() # node j\n",
    "        \n",
    "        prop =[g_D.ep[p] for p in dict(g_D.edge_properties).keys()]\n",
    "        all_edges_i = np.array([e for e in g_D.get_all_edges(i,eprops=prop) if e[1] ==j])\n",
    "        all_edges_j = np.array([e for e in g_D.get_all_edges(j,eprops=prop) if e[1] ==i])\n",
    "        \n",
    "        ni = len(all_edges_i) \n",
    "        nj = len(all_edges_j)\n",
    "\n",
    "        # -  Computing rec and non_rec lists\n",
    "        # - At least one reciprocal bw ij \n",
    "        if ni>0 and nj>0:\n",
    "            list_events= np.concatenate((all_edges_i, all_edges_j))\n",
    "            list_events = sorted(list_events, key = lambda x: x[5])\n",
    "            \n",
    "            # Counting number of reciprocal \n",
    "            binary_reciprocal = ''.join(['0' if list_events[k+1][1]==list_events[k][1] else '1' for k in range(len(list_events)-1)])\n",
    "            n_rec = binary_reciprocal.count('1')\n",
    "        \n",
    "            \n",
    "        # - Non Reciprocal events bw ij ( at all: no event is reciprocal bw there two)\n",
    "        elif (ni>0 and nj==0) or (ni==0 and nj>0):            \n",
    "            if ni>0 and nj==0:\n",
    "                list_events= np.copy(all_edges_i)  \n",
    "            elif ni==0 and nj>0:\n",
    "                list_events= np.copy(all_edges_j)\n",
    "            n_rec = 0 \n",
    "        \n",
    "        \n",
    "        # -  Intertimes of the link ij\n",
    "        intertimes = [list_events[k+1][5]-list_events[k][5]  for k in range(len(list_events)-1)]\n",
    "        \n",
    "        # -  Balance\n",
    "        be = max(ni,nj)/(ni+nj)\n",
    "        g.ep.balance[e] = be\n",
    "        \n",
    "        # -  P-rec at link level:\n",
    "        if (ni+nj-1) == 0: \n",
    "            p_Erec = np.NaN\n",
    "        else:\n",
    "            p_Erec = n_rec/(ni+nj-1)\n",
    "        g.ep.p_Erec[e] = p_Erec\n",
    "        \n",
    "        # - Intertime \n",
    "        g.ep.intertime[e] = np.array(intertimes)\n",
    "        \n",
    "        # - Burstiness\n",
    "        burts = burstiness(intertimes)\n",
    "        g.ep.burts[e] = burts\n",
    "        \n",
    "        # - Number of events between two nodes\n",
    "        g.ep.n_events[e] = len(list_events)\n",
    "        \n",
    "        ite +=1\n",
    "    return g"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "g= compute_link_prop(g,g_D)\n",
    "\n",
    "graph_draw(g, vertex_text= g.vertex_index, edge_text= g.ep.p_Erec,output_size=(250, 250) )\n",
    "graph_draw(g_D, vertex_text= g_D.vertex_index, edge_text= g_D.ep.ts_sec, output_size=(250, 250) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN & SAVE"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Note the edge and nodes properties will be saved  on g!!!\n",
    "ie. on the aggregate static network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading mentions\n",
      "computing mentions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-b5eff0caa753>:8: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return((std-mean)/(std+mean))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  edges n: 284338/284338saving mentions\n",
      "loading retweets\n",
      "computing retweets\n",
      "  edges n: 298460/298460saving retweets\n",
      "loading reply\n",
      "computing reply\n",
      "  edges n: 17180/17180saving reply\n"
     ]
    }
   ],
   "source": [
    "names = ['test', 'calls', 'sms','msg','email'] \n",
    "names =['mentions','retweets','reply']\n",
    "\n",
    "for i in range(len(names)):\n",
    "    name = names[i]\n",
    "    print('loading '+name)\n",
    "    \n",
    "    g_D = load_graph('./graphs_raw/'+name+\"_g_d.xml.gz\")\n",
    "    g = load_graph('./graphs_raw/'+name+\"_g.xml.gz\")\n",
    "    \n",
    "    print('computing '+name)\n",
    "    \n",
    "    # Do stuff on nodes\n",
    "    g = rec_nodes(g_D,g)\n",
    "    g = burst_rec_nodes(g_D,g)\n",
    "    g = burst_no_rec_nodes(g_D,g)\n",
    "    g = burst_nodes(g_D,g)\n",
    "    \n",
    "    # Do stuff on edges\n",
    "    g= compute_link_prop(g,g_D)\n",
    "        \n",
    "    # Save \n",
    "    print('saving '+name)\n",
    "    name_store = open('./graphs_fin/'+name+\"_g.pkl\", \"wb\")\n",
    "    pickle.dump(g,name_store)\n",
    "    name_store.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TABLE \n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['test', 'calls', 'sms','msg','email','mentions','retweets','reply']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table(name):\n",
    "    \n",
    "    # - Uploading graphs only g\n",
    "    #-------------------------------------    \n",
    "    name_store = open('./graphs_fin/'+name+\"_g.pkl\", \"rb\")\n",
    "    g = pickle.load(name_store)\n",
    "    name_store.close()\n",
    "    \n",
    "\n",
    "    # FILTERING\n",
    "    #-------------------------------------\n",
    "    \n",
    "    # a. (node filtering) Removing nodes with no reciprocal ecents\n",
    "    g_filt = GraphView(g, vfilt=lambda v: g.vp.n_rec_event[v] > 0.0)\n",
    "    \n",
    "    # b. (edge filtering) Removing unique edges bw two nodes (ie. if only one event bw two nodes)\n",
    "    g_filt = GraphView(g_filt, efilt=lambda e: g_filt.ep.n_events[e] != 1.0)\n",
    "    \n",
    "    \n",
    "    # OLDD OKK ??? \n",
    "    #Filtering in and out degree (keep only nodes with degree >=1)\n",
    "    #g_D_filt = GraphView(g_D, vfilt=lambda v: (v.out_degree()>=1)&(v.in_degree()>=1))\n",
    "    #g_filt = GraphView(g, vfilt=lambda v: (v in g_D_filt.vertices())==True)\n",
    "\n",
    "    \n",
    "    # TABLE\n",
    "    #-------------------------------------\n",
    "    DATA = {}\n",
    "    DATA['Nber_events'] = sum([g_filt.ep.n_events[v] for v in g_filt.edges()])\n",
    "    DATA['Nber_links'] = g_filt.num_edges()\n",
    "    DATA['Nber_nodes'] = g_filt.num_vertices() \n",
    "    \n",
    "    DATA['Proba_rec_event'] = np.mean([g_filt.ep.p_Erec[v] for v in g_filt.edges()])\n",
    "    DATA['Proba_rec_edge'] = sum([1 for v in g_filt.edges() if g_filt.ep.p_Erec[v]!= 0]) / g_filt.num_edges()\n",
    "    \n",
    "    DATA['Burst_nodes'] = np.mean([g_filt.vp.burst[v] for v in g_filt.vertices()])\n",
    "    DATA['Burst_edges'] = np.mean([g_filt.ep.burts[e] for e in g_filt.edges()])\n",
    "    \n",
    "    return(DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------ end :D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
